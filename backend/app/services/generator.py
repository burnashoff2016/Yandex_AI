import json
from typing import Dict, List, Optional, Any
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from openai import AsyncOpenAI
import httpx
from app.core.config import settings
from app.models.models import BrandVoice
from app.schemas.schemas import GenerateRequest, GoalEnum, ToneEnum, ChannelResult


SYSTEM_PROMPT = """–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π SMM-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –∏ –º–∞—Ä–∫–µ—Ç–æ–ª–æ–≥ —Å 10-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º. –°–æ–∑–¥–∞—ë—à—å –ø—Ä–æ–¥–∞—é—â–∏–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã—Ö –∫–∞–Ω–∞–ª–æ–≤.

–ü–†–ò–ù–¶–ò–ü–´:
- –ü–∏—à–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –∂–∏–≤–æ
- –ò—Å–ø–æ–ª—å–∑—É–π —Ç—Ä–∏–≥–≥–µ—Ä—ã: —Å—Ä–æ—á–Ω–æ—Å—Ç—å, —ç–∫—Å–∫–ª—é–∑–∏–≤–Ω–æ—Å—Ç—å, —Å—Ç—Ä–∞—Ö —É–ø—É—Å—Ç–∏—Ç—å
- –í—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–∞–π –ø—Ä–∏–∑—ã–≤ –∫ –¥–µ–π—Å—Ç–≤–∏—é (CTA)
- –û—Ü–µ–Ω–∏–≤–∞–π –∫–∞—á–µ—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–∞ –æ—Ç 1 –¥–æ 10
- –î–∞–≤–∞–π 1-2 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
- –í—Å–µ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–π –ø—Ä–æ–¥–∞—é—â–∏–µ —Ö–µ—à—Ç–µ–≥–∏ –¥–ª—è Telegram, VK, –î–∑–µ–Ω

–§–û–†–ú–ê–¢–´:

–Ø–ù–î–ï–ö–°.–î–ò–†–ï–ö–¢: –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ 35 —Å–∏–º–≤–æ–ª–æ–≤ | —Ç–µ–∫—Å—Ç –¥–æ 81 —Å–∏–º–≤–æ–ª–∞. –õ–∞–∫–æ–Ω–∏—á–Ω–æ, —Ü–∏—Ñ—Ä—ã, –≤—ã–≥–æ–¥–∞.

TELEGRAM: –¥–æ 800 —Å–∏–º–≤–æ–ª–æ–≤, 2-4 —ç–º–æ–¥–∑–∏, –∂–∏–≤–æ–π —Å—Ç–∏–ª—å, –≤ –∫–æ–Ω—Ü–µ —Ö–µ—à—Ç–µ–≥–∏. –î—Ä—É–∂–µ–ª—é–±–Ω–æ.

EMAIL: —Ç–µ–º–∞ –¥–æ 50 —Å–∏–º–≤–æ–ª–æ–≤, —Ç–µ–∫—Å—Ç –¥–æ 500 —Å–∏–º–≤–æ–ª–æ–≤. –í–µ–∂–ª–∏–≤–æ, –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ.

VK: –¥–æ 500 —Å–∏–º–≤–æ–ª–æ–≤, —ç–º–æ–¥–∑–∏, –≤–æ–ø—Ä–æ—Å—ã –∫ –∞—É–¥–∏—Ç–æ—Ä–∏–∏, —Ö–µ—à—Ç–µ–≥–∏. –†–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–π —Å—Ç–∏–ª—å.

–î–ó–ï–ù: –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–Ω—Ç—Ä–∏–≥—É—é—â–∏–π –¥–æ 80 —Å–∏–º–≤–æ–ª–æ–≤, —Ç–µ–∫—Å—Ç-–ª–æ–Ω–≥—Ä–∏–¥ 500-1500 —Å–∏–º–≤–æ–ª–æ–≤, –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏, –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Ö–µ—à—Ç–µ–≥–∏."""


FORMAT_INSTRUCTIONS = {
    "short": "–§–û–†–ú–ê–¢: –ö–æ—Ä–æ—Ç–∫–∏–π –ø–æ—Å—Ç –¥–æ 200 —Å–ª–æ–≤. –õ–∞–∫–æ–Ω–∏—á–Ω–æ, –ø–æ –¥–µ–ª—É, –æ–¥–∏–Ω –∫–ª—é—á–µ–≤–æ–π –º–µ—Å—Å–µ–¥–∂.",
    "longread": "–§–û–†–ú–ê–¢: –õ–æ–Ω–≥—Ä–∏–¥ 500-1000 —Å–ª–æ–≤. –†–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª —Å –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏, –ø—Ä–∏–º–µ—Ä–∞–º–∏, –≤—ã–≤–æ–¥–∞–º–∏.",
    "case_study": "–§–û–†–ú–ê–¢: –ö–µ–π—Å. –°—Ç—Ä—É–∫—Ç—É—Ä–∞: –ü—Ä–æ–±–ª–µ–º–∞ ‚Üí –†–µ—à–µ–Ω–∏–µ ‚Üí –†–µ–∑—É–ª—å—Ç–∞—Ç. –¶–∏—Ñ—Ä—ã, —Ñ–∞–∫—Ç—ã, –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞.",
    "story": "–§–û–†–ú–ê–¢: –ò—Å—Ç–æ—Ä–∏—è. –ó–∞–≤—è–∑–∫–∞ ‚Üí –†–∞–∑–≤–∏—Ç–∏–µ ‚Üí –ö—É–ª—å–º–∏–Ω–∞—Ü–∏—è ‚Üí –§–∏–Ω–∞–ª. –≠–º–æ—Ü–∏–∏, –ª–∏—á–Ω—ã–π –æ–ø—ã—Ç."
}


GOAL_INSTRUCTIONS = {
    GoalEnum.SALES: "–¶–ï–õ–¨: –ü—Ä–æ–¥–∞–∂–∞. –§–æ–∫—É—Å –Ω–∞ –≤—ã–≥–æ–¥–µ, —Å–∫–∏–¥–∫–∞—Ö, –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–∏, CTA –Ω–∞ –ø–æ–∫—É–ø–∫—É.",
    GoalEnum.AWARENESS: "–¶–ï–õ–¨: –£–∑–Ω–∞–≤–∞–µ–º–æ—Å—Ç—å. –§–æ–∫—É—Å –Ω–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏, —ç–º–æ—Ü–∏—è—Ö, –∏—Å—Ç–æ—Ä–∏–∏ –±—Ä–µ–Ω–¥–∞.",
    GoalEnum.ENGAGEMENT: "–¶–ï–õ–¨: –í–æ–≤–ª–µ—á–µ–Ω–∏–µ. –§–æ–∫—É—Å –Ω–∞ –≤–æ–ø—Ä–æ—Å–∞—Ö, –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–µ, –æ–±—Å—É–∂–¥–µ–Ω–∏–∏.",
    GoalEnum.ANNOUNCEMENT: "–¶–ï–õ–¨: –ê–Ω–æ–Ω—Å. –§–æ–∫—É—Å –Ω–∞ —á—Ç–æ/–≥–¥–µ/–∫–æ–≥–¥–∞, –ø–æ—á–µ–º—É –≤–∞–∂–Ω–æ —É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å."
}


TONE_INSTRUCTIONS = {
    ToneEnum.FORMAL: "–¢–û–ù: –§–æ—Ä–º–∞–ª—å–Ω—ã–π, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π.",
    ToneEnum.FRIENDLY: "–¢–û–ù: –î—Ä—É–∂–µ–ª—é–±–Ω—ã–π, —Ç—ë–ø–ª—ã–π.",
    ToneEnum.BOLD: "–¢–û–ù: –î–µ—Ä–∑–∫–∏–π, —Å–º–µ–ª—ã–π, —Å —é–º–æ—Ä–æ–º.",
    ToneEnum.EXPERT: "–¢–û–ù: –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π, –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π, —Å —Ñ–∞–∫—Ç–∞–º–∏."
}


def build_prompt(
    request: GenerateRequest,
    brand_voice: str = "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π, –Ω–æ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —Å—Ç–∏–ª—å."
) -> str:
    from app.schemas.schemas import PostFormatEnum
    
    variants_hint = f"–ø–æ {request.num_variants} –≤–∞—Ä–∏–∞–Ω—Ç–∞" if request.num_variants > 1 else "–≤–∞—Ä–∏–∞–Ω—Ç"
    
    goal_instruction = GOAL_INSTRUCTIONS.get(request.goal, GOAL_INSTRUCTIONS[GoalEnum.SALES])
    tone_instruction = TONE_INSTRUCTIONS.get(request.tone, TONE_INSTRUCTIONS[ToneEnum.FRIENDLY])
    
    audience_text = f"\n–¶–ê: {request.audience}" if request.audience else ""
    offer_text = f"\n–û—Ñ—Ñ–µ—Ä: {request.offer}" if request.offer else ""
    
    format_instruction = ""
    if request.format and request.format != PostFormatEnum.SHORT:
        format_instruction = f"\n{FORMAT_INSTRUCTIONS.get(request.format.value if hasattr(request.format, 'value') else request.format, '')}"
    
    channels_list = ", ".join(request.channels)
    
    prompt = f"""{goal_instruction}
{tone_instruction}{audience_text}{offer_text}{format_instruction}

–°—Ç–∏–ª—å –±—Ä–µ–Ω–¥–∞: {brand_voice}

–ó–ê–î–ê–ß–ê: –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π {variants_hint} —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∫–∞–Ω–∞–ª–æ–≤: {channels_list}

–ü—Ä–æ–¥—É–∫—Ç/–∞–∫—Ü–∏—è:
{request.description}

–í–ï–†–ù–ò JSON (—Ç–æ–ª—å–∫–æ JSON, –±–µ–∑ markdown):
{{
  "–î–∏—Ä–µ–∫—Ç": [
    {{"headline": "...", "body": "...", "cta": "...", "score": 8.5, "improvements": ["..."]}}
  ],
  "Telegram": [
    {{"body": "...", "hashtags": ["#..."], "cta": "...", "score": 9.0, "improvements": ["..."]}}
  ],
  "Email": [
    {{"headline": "—Ç–µ–º–∞", "body": "...", "cta": "...", "score": 8.0, "improvements": ["..."]}}
  ],
  "VK": [
    {{"body": "...", "hashtags": ["#..."], "cta": "...", "score": 8.5, "improvements": ["..."]}}
  ],
  "–î–∑–µ–Ω": [
    {{"headline": "–∏–Ω—Ç—Ä–∏–≥—É—é—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫", "body": "–ª–æ–Ω–≥—Ä–∏–¥ —Ç–µ–∫—Å—Ç...", "image_prompt": "–æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–∫–∏", "hashtags": ["#..."], "cta": "...", "score": 8.5, "improvements": ["..."]}}
  ]
}}

–í–∞–∂–Ω–æ:
- –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª—ã
- –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–∞–ª–∞ —Ä–æ–≤–Ω–æ {request.num_variants} –≤–∞—Ä–∏–∞–Ω—Ç(–∞) –≤ –º–∞—Å—Å–∏–≤–µ
- score –æ—Ç 1 –¥–æ 10
- improvements ‚Äî 1-2 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
- –í–∞—Ä–∏–∞–Ω—Ç—ã –¥–æ–ª–∂–Ω—ã –æ—Ç–ª–∏—á–∞—Ç—å—Å—è!
- –î–ª—è Telegram, VK, –î–∑–µ–Ω –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ–±–∞–≤—å 3-5 –ø—Ä–æ–¥–∞—é—â–∏—Ö —Ö–µ—à—Ç–µ–≥–æ–≤
- –î–ª—è –î–∑–µ–Ω –¥–æ–±–∞–≤—å image_prompt ‚Äî –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏"""

    return prompt


def parse_llm_response(response_text: str, channels: List[str], num_variants: int) -> Dict[str, List[ChannelResult]]:
    try:
        response_text = response_text.strip()
        if response_text.startswith("```json"):
            response_text = response_text[7:]
        if response_text.startswith("```"):
            response_text = response_text[3:]
        if response_text.endswith("```"):
            response_text = response_text[:-3]
        
        raw_result = json.loads(response_text.strip())
        
        result: Dict[str, List[ChannelResult]] = {}
        
        for channel in channels:
            channel_data = None
            for key in raw_result:
                if channel.lower() in key.lower() or key.lower() in channel.lower():
                    channel_data = raw_result[key]
                    break
            
            if channel_data is None:
                result[channel] = [ChannelResult(
                    body=f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –¥–ª—è {channel}",
                    score=0,
                    improvements=["–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å"]
                ) for _ in range(num_variants)]
                continue
            
            if not isinstance(channel_data, list):
                channel_data = [channel_data]
            
            parsed_variants = []
            for v in channel_data[:num_variants]:
                if isinstance(v, str):
                    parsed_variants.append(ChannelResult(body=v, score=7.0))
                elif isinstance(v, dict):
                    parsed_variants.append(ChannelResult(
                        headline=v.get("headline"),
                        body=v.get("body", v.get("text", "")),
                        cta=v.get("cta"),
                        hashtags=v.get("hashtags"),
                        image_prompt=v.get("image_prompt"),
                        score=float(v.get("score", 7.0)),
                        improvements=v.get("improvements")
                    ))
            
            while len(parsed_variants) < num_variants:
                parsed_variants.append(ChannelResult(
                    body=f"–í–∞—Ä–∏–∞–Ω—Ç {len(parsed_variants) + 1}",
                    score=5.0,
                    improvements=["–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç"]
                ))
            
            result[channel] = parsed_variants
        
        return result
        
    except json.JSONDecodeError as e:
        return {ch: [ChannelResult(
            body="–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.",
            score=0,
            improvements=[f"–û—à–∏–±–∫–∞: {str(e)[:50]}"]
        ) for _ in range(num_variants)] for ch in channels}
    except Exception as e:
        return {ch: [ChannelResult(
            body="–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.",
            score=0,
            improvements=[str(e)[:50]]
        ) for _ in range(num_variants)] for ch in channels}


async def get_brand_voice(db: AsyncSession, channel: Optional[str] = None) -> str:
    if channel:
        result = await db.execute(select(BrandVoice).where(BrandVoice.channel == channel))
        brand_voice = result.scalar_one_or_none()
        if brand_voice:
            return brand_voice.content
    
    result = await db.execute(select(BrandVoice).where(BrandVoice.channel == "general"))
    brand_voice = result.scalar_one_or_none()
    if brand_voice:
        return brand_voice.content
    
    return "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π, –Ω–æ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —Å—Ç–∏–ª—å."


async def generate_with_openai(prompt: str) -> str:
    client = AsyncOpenAI(
        api_key=settings.OPENAI_API_KEY,
        base_url=getattr(settings, 'LLM_BASE_URL', None)
    )
    
    response = await client.chat.completions.create(
        model=settings.LLM_MODEL,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt}
        ],
        temperature=0.8,
        max_tokens=4000
    )
    
    return response.choices[0].message.content or ""


async def generate_with_yandex(prompt: str) -> str:
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "https://llm.api.cloud.yandex.net/foundationModels/v1/completion",
            headers={
                "Authorization": f"Api-Key {settings.YANDEX_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "modelUri": f"gpt://{settings.YANDEX_API_KEY}/yandexgpt/latest",
                "completionOptions": {
                    "stream": False,
                    "temperature": 0.8,
                    "maxTokens": 4000
                },
                "messages": [
                    {"role": "system", "text": SYSTEM_PROMPT},
                    {"role": "user", "text": prompt}
                ]
            },
            timeout=60.0
        )
        response.raise_for_status()
        data = response.json()
        return data["result"]["alternatives"][0]["message"]["text"]


def generate_mock_response(request: GenerateRequest) -> Dict[str, List[ChannelResult]]:
    mock_data: Dict[str, List[ChannelResult]] = {}
    
    for channel in request.channels:
        variants = []
        for i in range(request.num_variants):
            if channel == "–î–∏—Ä–µ–∫—Ç":
                variants.append(ChannelResult(
                    headline=f"–°–∫–∏–¥–∫–∞ {20 + i*10}%!",
                    body=f"–¢–æ–ª—å–∫–æ —Å–µ–≥–æ–¥–Ω—è. –í–∞—Ä–∏–∞–Ω—Ç {i+1}",
                    cta="–ó–∞–∫–∞–∑–∞—Ç—å",
                    score=8.0 + i * 0.5,
                    improvements=["–î–æ–±–∞–≤—å—Ç–µ –¥–µ–¥–ª–∞–π–Ω"]
                ))
            elif channel == "Telegram":
                variants.append(ChannelResult(
                    body=f"üî• –í–∞—Ä–∏–∞–Ω—Ç {i+1}! –û—Ç–ª–∏—á–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏!\n\n–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –ø–æ —Å—Å—ã–ª–∫–µ üëá",
                    hashtags=["#–∞–∫—Ü–∏—è", "#—Å–∫–∏–¥–∫–∏"],
                    cta="–ü–æ–¥—Ä–æ–±–Ω–µ–µ",
                    score=8.5 + i * 0.3,
                    improvements=["–î–æ–±–∞–≤—å—Ç–µ —ç–º–æ–¥–∑–∏"]
                ))
            elif channel == "Email":
                variants.append(ChannelResult(
                    headline=f"–í–∞—Ä–∏–∞–Ω—Ç {i+1}: –≠–∫—Å–∫–ª—é–∑–∏–≤–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ",
                    body="–£–≤–∞–∂–∞–µ–º—ã–π –∫–ª–∏–µ–Ω—Ç! –†–∞–¥—ã –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –≤–∞–º...",
                    cta="–ü–æ–ª—É—á–∏—Ç—å",
                    score=7.5 + i * 0.5,
                    improvements=["–ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ"]
                ))
            elif channel == "VK":
                variants.append(ChannelResult(
                    body=f"üéâ –í–∞—Ä–∏–∞–Ω—Ç {i+1} –¥–ª—è –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤!\n\n–ü–∏—à–∏—Ç–µ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö! üëá",
                    hashtags=["#–∞–∫—Ü–∏—è", "#–¥–ª—è—Å–≤–æ–∏—Ö"],
                    cta="–£—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å",
                    score=8.0 + i * 0.4,
                    improvements=["–î–æ–±–∞–≤—å—Ç–µ –≤–æ–ø—Ä–æ—Å"]
                ))
            elif channel == "–î–∑–µ–Ω":
                variants.append(ChannelResult(
                    headline=f"–í–∞—Ä–∏–∞–Ω—Ç {i+1}: –ó–∞–≥–æ–ª–æ–≤–æ–∫, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–∏–≤–ª–µ–∫–∞–µ—Ç –≤–Ω–∏–º–∞–Ω–∏–µ",
                    body=f"–≠—Ç–æ –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –Ø–Ω–¥–µ–∫—Å.–î–∑–µ–Ω. –ó–¥–µ—Å—å –ø–æ–¥—Ä–æ–±–Ω–æ —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ–º –æ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞—Ö –ø—Ä–æ–¥—É–∫—Ç–∞ –∏ –ø–æ—á–µ–º—É —Å—Ç–æ–∏—Ç –≤—ã–±—Ä–∞—Ç—å –∏–º–µ–Ω–Ω–æ –µ–≥–æ.\n\n–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:\n‚Ä¢ –ü–µ—Ä–≤–æ–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ\n‚Ä¢ –í—Ç–æ—Ä–æ–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ\n‚Ä¢ –¢—Ä–µ—Ç—å–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ\n\n–ó–∞–∫–∞–∂–∏—Ç–µ –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å!",
                    image_prompt=f"Professional marketing image for social media, product showcase, modern style, variant {i+1}",
                    hashtags=["#–ø—Ä–æ–¥—É–∫—Ç", "#–ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞"],
                    cta="–ü–æ–¥—Ä–æ–±–Ω–µ–µ",
                    score=8.5 + i * 0.3,
                    improvements=["–î–æ–±–∞–≤—å—Ç–µ –ª–∏—á–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é"]
                ))
        mock_data[channel] = variants
    
    return mock_data


async def generate_content(
    request: GenerateRequest,
    db: AsyncSession
) -> Dict[str, List[ChannelResult]]:
    if settings.MOCK_MODE:
        return generate_mock_response(request)
    
    brand_voice = await get_brand_voice(db)
    prompt = build_prompt(request, brand_voice)
    
    try:
        if settings.LLM_PROVIDER == "yandex" and settings.YANDEX_API_KEY:
            response_text = await generate_with_yandex(prompt)
        elif settings.OPENAI_API_KEY:
            response_text = await generate_with_openai(prompt)
        else:
            return generate_mock_response(request)
        
        results = parse_llm_response(response_text, request.channels, request.num_variants)
        
        for channel, variants in results.items():
            for i, variant in enumerate(variants):
                if variant.image_prompt:
                    try:
                        from app.services.media import generate_image
                        image_response = await generate_image(variant.image_prompt, channel, db)
                        results[channel][i] = ChannelResult(
                            headline=variant.headline,
                            body=variant.body,
                            cta=variant.cta,
                            hashtags=variant.hashtags,
                            image_prompt=variant.image_prompt,
                            image_url=image_response.image_url,
                            score=variant.score,
                            improvements=variant.improvements
                        )
                    except Exception as e:
                        print(f"Image generation failed for {channel}: {e}")
        
        return results
    except Exception as e:
        print(f"Error generating content: {e}")
        return generate_mock_response(request)
