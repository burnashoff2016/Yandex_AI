import httpx
from openai import AsyncOpenAI
from app.core.config import settings
from app.schemas.schemas import ImproveAction


ACTION_PROMPTS = {
    ImproveAction.SHORTEN: """Ð¡Ð¾ÐºÑ€Ð°Ñ‚Ð¸ Ñ‚ÐµÐºÑÑ‚, ÑÐ¾Ñ…Ñ€Ð°Ð½Ð¸Ð² Ð³Ð»Ð°Ð²Ð½Ñ‹Ð¹ ÑÐ¼Ñ‹ÑÐ» Ð¸ CTA.
Ð£Ð±ÐµÑ€Ð¸ Ð»Ð¸ÑˆÐ½Ð¸Ðµ ÑÐ»Ð¾Ð²Ð°, ÑÐ´ÐµÐ»Ð°Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð»Ð°ÐºÐ¾Ð½Ð¸Ñ‡Ð½ÐµÐµ.
ÐžÑÑ‚Ð°Ð²ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚Ñ‹.
Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž ÑÐ¾ÐºÑ€Ð°Ñ‰Ñ‘Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð±ÐµÐ· Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ð¹.""",

    ImproveAction.EMOJI: """Ð”Ð¾Ð±Ð°Ð²ÑŒ 2-4 Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ñ… ÑÐ¼Ð¾Ð´Ð·Ð¸ Ð² Ñ‚ÐµÐºÑÑ‚.
Ð Ð°ÑÑÑ‚Ð°Ð²ÑŒ ÑÐ¼Ð¾Ð´Ð·Ð¸ Ð¾Ñ€Ð³Ð°Ð½Ð¸Ñ‡Ð½Ð¾, Ð½Ðµ Ð¿ÐµÑ€ÐµÐ³Ñ€ÑƒÐ¶Ð°Ð¹.
Ð­Ð¼Ð¾Ð´Ð·Ð¸ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¾Ð²Ð°Ñ‚ÑŒ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ.
Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž Ñ‚ÐµÐºÑÑ‚ Ñ ÑÐ¼Ð¾Ð´Ð·Ð¸ Ð±ÐµÐ· Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ð¹.""",

    ImproveAction.TONE: """Ð˜Ð·Ð¼ÐµÐ½Ð¸ Ñ‚Ð¾Ð½ Ñ‚ÐµÐºÑÑ‚Ð° Ð½Ð° {target_tone}.
ÐŸÐµÑ€ÐµÐ¿Ð¸ÑˆÐ¸ Ñ‚ÐµÐºÑÑ‚, ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑ ÑÐ¼Ñ‹ÑÐ», Ð½Ð¾ Ð¸Ð·Ð¼ÐµÐ½Ð¸Ð² ÑÑ‚Ð¸Ð»ÑŒ.
Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž Ð¿ÐµÑ€ÐµÐ¿Ð¸ÑÐ°Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð±ÐµÐ· Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ð¹.""",

    ImproveAction.CTA: """Ð£Ð»ÑƒÑ‡ÑˆÐ¸ Ð¿Ñ€Ð¸Ð·Ñ‹Ð² Ðº Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸ÑŽ (CTA) Ð² Ñ‚ÐµÐºÑÑ‚Ðµ.
Ð¡Ð´ÐµÐ»Ð°Ð¹ CTA Ð±Ð¾Ð»ÐµÐµ ÑƒÐ±ÐµÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼ Ð¸ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ð¼.
Ð”Ð¾Ð±Ð°Ð²ÑŒ ÑÑ€Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ Ð¸Ð»Ð¸ Ð²Ñ‹Ð³Ð¾Ð´Ñƒ, ÐµÑÐ»Ð¸ ÑƒÐ¼ÐµÑÑ‚Ð½Ð¾.
Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž Ñ‚ÐµÐºÑÑ‚ Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ð¼ CTA Ð±ÐµÐ· Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ð¹."""
}

CHANNEL_CONSTRAINTS = {
    "Ð”Ð¸Ñ€ÐµÐºÑ‚": "Ð”Ð»Ð¸Ð½Ð° Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ° Ð´Ð¾ 35 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð², Ñ‚ÐµÐºÑÑ‚ Ð´Ð¾ 81 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð°.",
    "Telegram": "Ð”Ð»Ð¸Ð½Ð° Ð´Ð¾ 800 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð², Ð¼Ð¾Ð¶Ð½Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ ÑÐ¼Ð¾Ð´Ð·Ð¸.",
    "Email": "Ð¢ÐµÐ¼Ð° Ð´Ð¾ 50 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð², Ñ‚ÐµÐºÑÑ‚ Ð´Ð¾ 500 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð².",
    "VK": "Ð”Ð»Ð¸Ð½Ð° Ð´Ð¾ 500 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð², Ð¼Ð¾Ð¶Ð½Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ ÑÐ¼Ð¾Ð´Ð·Ð¸."
}


async def improve_with_openai(prompt: str, text: str, channel: str) -> str:
    client = AsyncOpenAI(
        api_key=settings.OPENAI_API_KEY,
        base_url=getattr(settings, 'LLM_BASE_URL', None)
    )
    
    channel_constraint = CHANNEL_CONSTRAINTS.get(channel, "")
    
    full_prompt = f"""{prompt}

ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ ÐºÐ°Ð½Ð°Ð»Ð°: {channel_constraint}

Ð˜ÑÑ…Ð¾Ð´Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚:
{text}"""
    
    response = await client.chat.completions.create(
        model=settings.LLM_MODEL,
        messages=[
            {"role": "system", "content": "Ð¢Ñ‹ â€” Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐ¾Ð¿Ð¸Ñ€Ð°Ð¹Ñ‚ÐµÑ€. Ð£Ð»ÑƒÑ‡ÑˆÐ°ÐµÑˆÑŒ Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¸Ð½Ð³Ð¾Ð²Ñ‹Ðµ Ñ‚ÐµÐºÑÑ‚Ñ‹ Ð´Ð»Ñ Ñ€Ð¾ÑÑÐ¸Ð¹ÑÐºÐ¸Ñ… ÐºÐ°Ð½Ð°Ð»Ð¾Ð²."},
            {"role": "user", "content": full_prompt}
        ],
        temperature=0.7,
        max_tokens=1000
    )
    
    return response.choices[0].message.content or text


async def improve_with_yandex(prompt: str, text: str, channel: str) -> str:
    channel_constraint = CHANNEL_CONSTRAINTS.get(channel, "")
    
    full_prompt = f"""{prompt}

ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ ÐºÐ°Ð½Ð°Ð»Ð°: {channel_constraint}

Ð˜ÑÑ…Ð¾Ð´Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚:
{text}"""
    
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "https://llm.api.cloud.yandex.net/foundationModels/v1/completion",
            headers={
                "Authorization": f"Api-Key {settings.YANDEX_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "modelUri": f"gpt://{settings.YANDEX_API_KEY}/yandexgpt/latest",
                "completionOptions": {
                    "stream": False,
                    "temperature": 0.7,
                    "maxTokens": 1000
                },
                "messages": [
                    {"role": "system", "text": "Ð¢Ñ‹ â€” Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐ¾Ð¿Ð¸Ñ€Ð°Ð¹Ñ‚ÐµÑ€. Ð£Ð»ÑƒÑ‡ÑˆÐ°ÐµÑˆÑŒ Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¸Ð½Ð³Ð¾Ð²Ñ‹Ðµ Ñ‚ÐµÐºÑÑ‚Ñ‹ Ð´Ð»Ñ Ñ€Ð¾ÑÑÐ¸Ð¹ÑÐºÐ¸Ñ… ÐºÐ°Ð½Ð°Ð»Ð¾Ð²."},
                    {"role": "user", "text": full_prompt}
                ]
            },
            timeout=30.0
        )
        response.raise_for_status()
        data = response.json()
        return data["result"]["alternatives"][0]["message"]["text"]


def mock_improve(text: str, action: ImproveAction, target_tone: str = None) -> str:
    if action == ImproveAction.SHORTEN:
        words = text.split()
        if len(words) > 10:
            return " ".join(words[:len(words)//2]) + "..."
        return text
    
    if action == ImproveAction.EMOJI:
        emojis = ["ðŸ”¥", "âœ¨", "ðŸš€", "ðŸ’¡", "ðŸ‘", "ðŸŽ‰"]
        import random
        result = text
        for _ in range(2):
            pos = random.randint(0, len(result))
            result = result[:pos] + random.choice(emojis) + result[pos:]
        return result
    
    if action == ImproveAction.TONE:
        tone_marker = f"[{target_tone or 'ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð½Ñ‹Ð¹'} Ñ‚Ð¾Ð½] "
        return tone_marker + text
    
    if action == ImproveAction.CTA:
        if "!" not in text:
            return text + " Ð—Ð°ÐºÐ°Ð¶Ð¸Ñ‚Ðµ ÑÐµÐ¹Ñ‡Ð°Ñ!"
        return text
    
    return text


async def improve_text(
    text: str,
    action: ImproveAction,
    channel: str,
    target_tone: str = None
) -> str:
    if settings.MOCK_MODE:
        return mock_improve(text, action, target_tone)
    
    prompt = ACTION_PROMPTS.get(action, ACTION_PROMPTS[ImproveAction.SHORTEN])
    
    if action == ImproveAction.TONE and target_tone:
        prompt = prompt.format(target_tone=target_tone)
    
    try:
        if settings.LLM_PROVIDER == "yandex" and settings.YANDEX_API_KEY:
            return await improve_with_yandex(prompt, text, channel)
        elif settings.OPENAI_API_KEY:
            return await improve_with_openai(prompt, text, channel)
        else:
            return mock_improve(text, action, target_tone)
    except Exception as e:
        print(f"Error improving text: {e}")
        return mock_improve(text, action, target_tone)
